{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Title: Star Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "There are billions of stars in our sky and every star is unique. There are brown, white, and red dwarfs, main sequence stars like the sun and also hyper and super giants. Each of these star types has unique characteristics which can be used to classify their type. Astronomers typically use features such as the stars Luminosity, Radius, and Temperature to determine its type. In this data analysis, we will look at a star dataset which includes features of 240 stars which includes 40 stars from each of the 6 categories. The features of stars this dataset includes is the surface temperature in Kelvins, the luminosity in solar luminosity, radius in solar radius, visual magnitude (How bright the star appears from a distance of 10 Kpc), star type, star colour, and stellar class. Luminosity is the amount of energy generated per second by the star and is given in stellar units. This means that a luminosity of 100 means 100 times more luminous than the sun. The radius is also how big it is in stellar units, and a radius of 10 means 10 times bigger than the sun. Researchers have used the Hertzsprung-Russell Diagram (A plot of Luminosity vs. Temperature) to plot star features in order to determine a star’s type. To further our understanding of this diagram, we want to utilize k-nn classification to imitate aspects of the diagram and predict a new star’s type. The question we will address is whether we can build a model which effectively, consistently, and accurately classifies a new star’s type using k-nn classification to classify stars based on it's luminosity, radius, and temperature. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methods & Results**\n",
    "\n",
    "In this data analysis, the plan is to build a model using temperature, radius, and luminosity. To start off we will set our seed value (2022) and load in all the libraries we need for this data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all libraries and set plot dimensions\n",
    "set.seed(2022)\n",
    "options(repr.plot.height = 8, repr.plot.width = 10)\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(dplyr)\n",
    "library(tidymodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset**\n",
    "\n",
    "Now we need to load in our dataset and analyze it by looking at first 6 and last 6 observations using tail and head functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data frame and changed the column names to more convenient\n",
    "url <- \"https://docs.google.com/spreadsheets/d/e/2PACX-1vR0bAqJh1jznOVyOZbHPL3kLbFjX6YzCWwMh3vMZEeBZq95tdDfcN9vqDP6XUf2j167vXr4oxnDvhb4/pub?gid=1536482276&single=true&output=csv\"\n",
    "star <- read_csv(url)\n",
    "\n",
    "head(star)\n",
    "tail(star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean and Wrangle Dataset**\n",
    "\n",
    "Looking at the dataset, the column names have spaces so it would be a good idea to rename the columns to more convenient names, to make it more convenient to use with functions such as mutate and filter. We also want to change the type of the variable we are trying to classify which is star_type to a factor. The person who created the dataset decided to map the star type in star_type column as a number. They mapped Brown Dwarfs as 0, Red Dwarfs as 1, White Dwarfs as 2, Main Sequence stars as 3, Super giants as 4, and Hyper Giants as 5. To make our data analysis easier to understand we will map the star types back to their actual name. Lastly, judging from these two tables it seems like it would be a great idea to apply the log10 function to our predictors which are luminosity, radius, and temperature because the smallest values and largest values of these variables differ by a very significant amount. For example the lowest values for luminosity are a lot smaller than 1 while the largest values are greater than 100,000 so for the purpose of this data analysis since applying log10 function to each individual predictor will only decrease the amount each value varies by in respect to each other and won't impact relationship between values of other predictor, applying log10 will not impact our results for the data analysis and will make our values simpler to work with and visualize. So lets apply all these changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns to more convenient name\n",
    "star_data <- star %>% \n",
    "    rename(star_type = \"Star type\",\n",
    "           star_color = \"Star color\",\n",
    "           spectral_class = \"Spectral Class\",\n",
    "           temperature = \"Temperature (K)\",\n",
    "           radius = \"Radius(R/Ro)\",\n",
    "           luminosity = \"Luminosity(L/Lo)\",\n",
    "           absolute_magnitude = \"Absolute magnitude(Mv)\") %>%\n",
    "    tibble()\n",
    "\n",
    "\n",
    "#Renamed numerical values of star type to their actual name \n",
    "star_data$star_type[star_data$star_type == 0] <- \"Brown Dwarf\"\n",
    "star_data$star_type[star_data$star_type == 1] <- \"Red Dwarf\"\n",
    "star_data$star_type[star_data$star_type == 2] <- \"White Dwarf\"\n",
    "star_data$star_type[star_data$star_type == 3] <- \"Main Sequence\"\n",
    "star_data$star_type[star_data$star_type == 4] <- \"Super Giant\"\n",
    "star_data$star_type[star_data$star_type == 5] <- \"Hyper Giant\"\n",
    "\n",
    "#Changed star_type to a factor and also applied log10 function to all predictors\n",
    "star_data <- star_data %>%\n",
    "    mutate(star_type = as_factor(star_type),\n",
    "          luminosity = log10(luminosity),\n",
    "          radius = log10(radius),\n",
    "          temperature = log10(temperature))\n",
    "\n",
    "sample_n(star_data, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be performing a knn classification, before doing any exploratory data analysis of our data we only want access to the training dataset and hide the test dataset. So lets split our dataset by using 60% of original dataset for the training set and 40% for the test set so we can have a fairly good balance between building an accurate model and have a large enough test dataset so we can get a precise accuracy for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into a training set and testing set \n",
    "star_split <- initial_split(star_data, prop = 0.6, strata = star_type)\n",
    "star_train <- training(star_split)\n",
    "star_test <- testing(star_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis: Dataset Summary**\n",
    "\n",
    "Now that the dataset has been split into a training and testing dataset, lets summarize our dataset by looking at the average temperature, average density, and average radius for each star type, as well as the number of stars included for each star type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot indicating the number of observations in each star type and averages of all predictor variables\n",
    "star_distribution <- star_train %>%\n",
    "    select(temperature, radius, luminosity, star_type) %>%\n",
    "    group_by(star_type) %>%\n",
    "    summarize(stars_in_class = n(), luminosity_avg = mean(luminosity), radius_avg = mean(radius), temperature_avg = mean(temperature))\n",
    "star_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from Table 1 that there are 24 stars from each star type included and brown dwarfs have the lowest luminosity value on average and Hyper giants have the largest luminosity value, White dwarfs have the smallest average radius and Hyper Giants have the largest average radius, and Brown Dwarfs have the lowest temperature average and White dwarfs have the highest temperature average. Judging from the low variability of temperature for the different star types, it may not be as good of a predictor for star type in comparison to Luminosity and Radius since their average values vary more between star types.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis: Visualizations**\n",
    "\n",
    "Now we will create three different visualizations to visualize the relationships between all the predictors and since we suspect that temperature might not be the best predictor for star type, we will create a histogram which shows the distribution temperature for all the star types. This will help us gain a better understanding of dataset and guide us in building the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of Luminosity vs. Temperature\n",
    "star_plot <- star_train %>%\n",
    "    ggplot(aes(x = temperature, y = luminosity, color = star_type)) + \n",
    "    geom_point() +\n",
    "    ggtitle(\"Luminosity(Log Scaled) vs. Surface Temperature(Log Scaled)\") +\n",
    "    labs(x = \"Surface Temperature(Log Scaled)\", y = \"Luminosity(Log Scaled)\", color = \"Star Type\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "star_plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luminosity and temperature seems to have a multiple relationships going on. For Main Sequence Stars, Red dwarfs, and Brown dwarfs, there is a strong positive linear relationship and there seems to be a moderate positive relationship for White Dwarfs and Hyper Giants and Super Giants don't have a relationship at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of Luminosity vs. Radius\n",
    "star_plot_2 <- star_train %>%\n",
    "    ggplot(aes(x = radius, y = luminosity, color = star_type)) + \n",
    "    geom_point() +\n",
    "    ggtitle(\"Luminosity(Log Scaled) vs. Radius(Log Scaled)\") +\n",
    "    labs(x = \"Radius(Log Scaled)\", y = \"Luminosity(Log Scaled)\", color = \"Star Type\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "star_plot_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luminosity and Radius have a strong positive non-linear relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of Temperature vs. Radius\n",
    "star_plot_3 <- star_train %>%\n",
    "    ggplot(aes(x = radius, y = temperature, color = star_type)) + \n",
    "    geom_point() +\n",
    "    ggtitle(\"Surface Temperature(Log Scaled) vs. Radius(Log Scaled)\") +\n",
    "    labs(x = \"Radius(Log Scaled)\", y = \"Surface Temperature(Log Scaled)\", color = \"Star Type\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "star_plot_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of figure 3, there is a Strong positive non-linear relationship between Temperature and Radius for Brown Dwarfs, Red Dwarfs, and Main Sequence stars but no relationship for the rest of the star types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot to see distribution of star type and temperature\n",
    "star_temp_plot <- star_train %>%\n",
    "    ggplot(aes(x = temperature, fill = star_type)) +\n",
    "    geom_histogram(position = \"fill\", color = \"lightgrey\", bins = 15) +\n",
    "    ggtitle(\"Star Type Distribution vs. Temperature\") +\n",
    "    labs(x = \"Temperature(Log Scaled)\", y = \"Star Type distribution\", color = \"Star Type\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "star_temp_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of Figure 4, there is too much star type variability for temperature. Temperatures from 3.4 to 3.6 and from around 3.8 to 5 include up to 2-4 different star types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion from Exploratory Data Analysis**\n",
    "\n",
    "After conducting the exploratory data analysis, based off of Table 1, Figure 1, Figure 3 and 4, we can hypothesize that Temperature may not be the best predictor as it might cause a some observations to be classified incorrectly. However, luminosity and radius seem to be very good predictors. So to start off by building a model by including temperature and then well build a model by excluding temperature and then we will apply cross validation to compare acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Star Vfold to apply cross-validation\n",
    "star_vfold <- vfold_cv(star_train, v = 10, strata = star_type)\n",
    "\n",
    "#K-nearest neighbor model specification: pre cross-validation\n",
    "knn_spec_temp <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\") \n",
    "\n",
    "#Recipe for star data and standardization\n",
    "star_recipe_temp <- recipe(star_type ~ radius + luminosity + temperature, data = star_train) %>%\n",
    "    step_scale(all_predictors()) %>%\n",
    "    step_center(all_predictors())\n",
    "\n",
    "#Put together everything into a workflow\n",
    "star_fit_temp <- workflow() %>%\n",
    "    add_recipe(star_recipe_temp) %>%\n",
    "    add_model(knn_spec_temp) %>%\n",
    "    tune_grid(resamples = star_vfold, grid = tibble(neighbors = seq(1,20)))\n",
    "\n",
    "# #Collect the summary of our cross-validation\n",
    "star_summary_temp <- star_fit_temp %>%\n",
    "    collect_metrics() %>%\n",
    "    filter(.metric == \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of accuracy vs. neighbors  \n",
    "star_accuracy_plot <- star_summary_temp %>%\n",
    "    ggplot(aes(x = neighbors, y = mean)) + \n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    ggtitle(\"Accuracy vs. Neighbors\") +\n",
    "    labs(x = \"Neighbors\", y = \"Accuracy\") +\n",
    "    theme(text = element_text(size = 20)) +\n",
    "    scale_x_continuous(breaks = 1:20)\n",
    "\n",
    "star_accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best K value\n",
    "k_min <- star_summary_temp %>%\n",
    "    arrange(desc(mean)) %>% \n",
    "    slice(1) %>%\n",
    "    select(neighbors) %>%\n",
    "    pull()\n",
    "\n",
    "k_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-nearest neighbor model specification: pre cross-validation\n",
    "knn_spec_temp <- nearest_neighbor(weight_func = \"rectangular\", neighbors = k_min) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\") \n",
    "\n",
    "#Put together everything into a workflow\n",
    "star_fit_temp <- workflow() %>%\n",
    "    add_recipe(star_recipe_temp) %>%\n",
    "    add_model(knn_spec_temp) %>%\n",
    "    fit_resamples(resamples = star_vfold)\n",
    "\n",
    "# #Collect the summary of our cross-validation\n",
    "star_summary_temp <- star_fit_temp %>%\n",
    "    collect_metrics() %>%\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "star_summary_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is quite high with temperature included but we want to test our hypothesis that our model will be better off without including temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-nearest neighbor model specification: pre cross-validation\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\") \n",
    "\n",
    "#Recipe for star data and standardization\n",
    "star_recipe <- recipe(star_type ~ radius + luminosity, data = star_train) %>%\n",
    "    step_scale(all_predictors()) %>%\n",
    "    step_center(all_predictors())\n",
    "\n",
    "#Put together everything into a workflow\n",
    "star_fit <- workflow() %>%\n",
    "    add_recipe(star_recipe) %>%\n",
    "    add_model(knn_spec) %>%\n",
    "    tune_grid(resamples = star_vfold, grid = tibble(neighbors = seq(1,20)))\n",
    "\n",
    "# #Collect the summary of our cross-validation\n",
    "star_summary <- star_fit %>%\n",
    "    collect_metrics() %>%\n",
    "    filter(.metric == \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of accuracy vs. neighbors  \n",
    "star_accuracy_plot <- star_summary %>%\n",
    "    ggplot(aes(x = neighbors, y = mean)) + \n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    ggtitle(\"Accuracy vs. Neighbors\") +\n",
    "    labs(x = \"Neighbors\", y = \"Accuracy\") +\n",
    "    theme(text = element_text(size = 20)) +\n",
    "    scale_x_continuous(breaks = 1:20)\n",
    "\n",
    "star_accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best K value\n",
    "k_min <- star_summary %>%\n",
    "    arrange(desc(mean)) %>% \n",
    "    slice(1) %>%\n",
    "    select(neighbors) %>%\n",
    "    pull()\n",
    "\n",
    "k_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrained model with new k value \n",
    "knn_best_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = k_min) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\") \n",
    "\n",
    "star_best_accuracy <- workflow() %>%\n",
    "    add_recipe(star_recipe) %>%\n",
    "    add_model(knn_best_spec) %>%\n",
    "    fit_resamples(resamples = star_vfold) %>%\n",
    "    collect_metrics() %>%\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "star_best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_best_fit <- workflow() %>%\n",
    "    add_recipe(star_recipe) %>%\n",
    "    add_model(knn_best_spec) %>%\n",
    "    fit(data = star_train) \n",
    "\n",
    "star_predictions <- star_best_fit %>%\n",
    "    predict(star_test) %>%\n",
    "    bind_cols(star_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_metrics <- star_predictions %>%\n",
    "    metrics(truth = star_type, estimate = .pred_class) %>%\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "star_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_conf_mat <- star_predictions %>%\n",
    "    conf_mat(truth = star_type, estimate = .pred_class)\n",
    "\n",
    "star_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the grid of area/smoothness vals, and arrange in a data frame\n",
    "lum_grid <- seq(min(star_data$luminosity), \n",
    "                max(star_data$luminosity), \n",
    "                length.out = 100)\n",
    "rad_grid <- seq(min(star_data$radius), \n",
    "                max(star_data$radius), \n",
    "                length.out = 100)\n",
    "asgrid <- tibble(expand.grid(luminosity = lum_grid, \n",
    "                                radius = rad_grid))\n",
    "\n",
    "star_final_fit <- workflow() %>%\n",
    "    add_recipe(star_recipe) %>%\n",
    "    add_model(knn_best_spec) %>%\n",
    "    fit(data = star_train)\n",
    "\n",
    "knnPredGrid <- predict(star_final_fit, asgrid)\n",
    "\n",
    "# bind the predictions as a new column with the grid points\n",
    "prediction_table <- bind_cols(knnPredGrid, asgrid) %>%\n",
    "  rename(Class = .pred_class)\n",
    "\n",
    "# plot:\n",
    "# 1. the colored scatter of the original data\n",
    "# 2. the faded colored scatter for the grid point\n",
    "wkflw_plot <-\n",
    "  ggplot() +\n",
    "  geom_point(data = star_data, \n",
    "             mapping = aes(x = radius, \n",
    "                           y = luminosity, \n",
    "                          color = star_type), \n",
    "             alpha = 0.75) +\n",
    "  geom_point(data = prediction_table, \n",
    "             mapping = aes(x = radius, \n",
    "                           y = luminosity, \n",
    "                           color = Class), \n",
    "             alpha = 0.06, \n",
    "             size = 5) +\n",
    "  labs(color = \"Diagnosis\", \n",
    "       x = \"Radius (Log Scaled)\", \n",
    "       y = \"Luminosity (Log Scaled)\") +\n",
    "  scale_color_manual(labels = c(\"White Dwarf\", \"Main Sequence\", \"Brown Dwarf\", \"Red Dwarf\", \"Hyper Giant\", \"Super Giant\"), \n",
    "                     values = c(\"azure4\", \"chartreuse4\", \"brown\", \"brown1\", \"darkorchid2\", \"deeppink1\")) +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "wkflw_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_accuracy <- star_best_fit %>%\n",
    "    predict(star_test) %>%\n",
    "    bind_cols(star_test) %>%\n",
    "    mutate(prediction = ifelse(.pred_class == star_type, \"correct\", \"incorrect\")) %>%\n",
    "    group_by(star_type, prediction) %>%\n",
    "    summarize(n = n())\n",
    "\n",
    "star_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_accuracy_plot <- star_accuracy %>%\n",
    "    ggplot(aes(x = star_type, y = n, fill = prediction)) +\n",
    "    geom_bar(stat = \"identity\", position = \"fill\") +\n",
    "    scale_fill_brewer(palette = \"RdYlBu\") +\n",
    "    ggtitle(\"Predictions vs. Star Type\") +\n",
    "    labs(x = \"Star Type\", y = \"Correct vs. Incorrect Proportion\", color = \"Predictions\") +\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "star_accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
